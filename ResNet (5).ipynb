{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9AxpUKHRzZJ",
        "colab_type": "text"
      },
      "source": [
        "<h1> **RESNET IMPLEMENTATION** </h1>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Importing important libraries and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2mHhZtPJKXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "\n",
        "torch.set_grad_enabled(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qov4k-68TXxj",
        "colab_type": "text"
      },
      "source": [
        "<h1> Basics architectural knowledge about ResNet </h1>\n",
        "\n",
        "ResNet stands for \"Residual Network\" which is a very logical name because, we stores the output of some network as **residue** and pass it as input in further layers in network. The basic aim of this network is to make a able to make very deep networks and yet not suffer with the problems like - \n",
        "\n",
        "1.   Vanishing Gradient\n",
        "2.   Overfitting\n",
        "\n",
        "And usage of **residue** further in network ensures that features will be reused and important informations are passed further in network that ensures meaningful features will be made. \n",
        "\n",
        "We can see the effects of vanishing gradient which messes with network in such a way that deeper network shows more error. We basically want to go deeper to prevent overfitting but the trade-off is too high. So, ResNet comes to rescue.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/935/1*McwAbGJjA1lV_xBdg1w5XA.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AlfOoEIciwk",
        "colab_type": "text"
      },
      "source": [
        "<h1> Overview of ResNet Architecture </h1>\n",
        "\n",
        "There are two types of blocks (combination of standard layers) we will be making -\n",
        "\n",
        "\n",
        "1.   Base Block - This is the simplest block of the following form \n",
        "\n",
        "  ![alt text](https://miro.medium.com/max/2678/1*BCbJZXwGDtEdytj9ag_YWw.png)\n",
        "\n",
        "\n",
        "\n",
        "*   1st weight layer is for changing the number of channels\n",
        "*   Then we activate it\n",
        "*   Then 2nd weight layer is for changing height and width of the filter\n",
        "*   Then we add the residue **X** to this output before activating it.\n",
        "*   Then relu(output + x)\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2.   BottleNeck Block - Since these research papers are made by really iterative process, another kind of block is preffered for deeper ResNet versions like ResNet50 or higher.\n",
        "\n",
        "  ![alt text](https://miro.medium.com/max/2621/1*sb_4xKI_bRoX6jmZcNTRWw.png)\n",
        "\n",
        "*   1st weight layer is for changing the number of channels\n",
        "*   Then we activate it\n",
        "*   Then 2nd weight layer is for changing height and width of the filter\n",
        "*   Then we activate it\n",
        "*   Then we pass it to a layer which expands the number of channels (mainly by a factor of 4)\n",
        "*   Then we add the residue **X** to this output before activating it. Sometime the dimension of **residue** is not same as the output of block. So, we perform a comvolution operation to make it to the size of output.\n",
        "*   Then relu(output + x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-paQMK0jJhVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class baseblock(nn.Module):\n",
        "  expansion=1\n",
        "  def __init__(self,input_planes,planes,stride=1,kernel_size=1,dim_change=None):\n",
        "    super().__init__()\n",
        "    #layer to change the dimension\n",
        "    self.conv1 = nn.Conv2d(input_planes,planes,kernel_size=1)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    #layer to change Height width of image\n",
        "    self.conv2 = nn.Conv2d(planes,planes,kernel_size=3,stride=stride,padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "    self.dim_change = nn.Sequential()\n",
        "    if stride!=1 or input_planes!=planes*expansion:\n",
        "      self.dim_change = nn.Sequential(nn.Conv2d(input_planes,planes*expansion,kernel_size=1,stride=stride)\n",
        "                                      nn.BatchNorm2d(planes*expansion))\n",
        "    \n",
        "    def forward(self,x):\n",
        "      res = x\n",
        "      #layer 1\n",
        "      out = self.conv1(x)\n",
        "      out = self.bn1(out)\n",
        "      out = F.relu(x)\n",
        "      #layer 2\n",
        "      out = self.conv2(out)\n",
        "      out = self.bn1(out)\n",
        "\n",
        "      out+=self.dim_change(res)\n",
        "      out=F.relu(out)\n",
        "      return out\n",
        "\n",
        "\n",
        "class bottleneck(nn.Module):\n",
        "  expansion=4\n",
        "  def __init__(self,input_planes,planes,stride=1,kernel_size=1,dim_change=None):\n",
        "    super().__init__()\n",
        "    #layer to change the dimension\n",
        "    self.conv1 = nn.Conv2d(input_planes,planes,kernel_size=1)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    #layer to change Height width of image\n",
        "    self.conv2 = nn.Conv2d(planes,planes,kernel_size=3,stride=stride,padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "    #layer for channel expansion and nothing else\n",
        "    self.conv3 = nn.Conv2d(planes,planes*self.expansion,kernel_size=1)\n",
        "    self.bn3 = nn.BatchNorm2d(planes*self.expansion)\n",
        "    self.dim_change = nn.Sequential()\n",
        "    if stride != 1 or input_planes != planes*self.expansion:\n",
        "      self.dim_change = nn.Sequential(nn.Conv2d(input_planes,planes*self.expansion,kernel_size=1,stride=stride),\n",
        "                                      nn.BatchNorm2d(planes*self.expansion))\n",
        "\n",
        "  def forward(self,x):\n",
        "    res=x\n",
        "\n",
        "    t=self.conv1(x)\n",
        "    t=self.bn1(t)\n",
        "    t=F.relu(t)\n",
        "    #t = F.Relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "    t=self.conv2(t)\n",
        "    t=self.bn2(t)\n",
        "    t=F.relu(t)\n",
        "    #t = F.Relu(self.bn2(self.conv2(t)))\n",
        "\n",
        "    t=self.conv3(t)\n",
        "    t=self.bn3(t)\n",
        "    #t = self.bn3(self.conv3(t))\n",
        "\n",
        "    t+=self.dim_change(res)\n",
        "    t=F.relu(t)\n",
        "\n",
        "    return t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eg7JuVBpceU",
        "colab_type": "text"
      },
      "source": [
        "<h1> What a ResNet Network looklike? </h1>\n",
        "\n",
        "Resnet architecture can be implemented in many ways using those blocks we studied before. Below are some standard configurations and ways of using ResNet to get nicely optimised output.\n",
        "![alt text](https://miro.medium.com/max/1849/1*aq0q7gCvuNUqnMHh4cpnIw.png)\n",
        "\n",
        "Below are the two types of block we have implemented before.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1103/1*zS2ChIMwAqC5DQbL5yD9iQ.png)\n",
        "\n",
        "In this article we are going to implement ResNet50 architecture from scratch using these blocks and train CIFAR-10 dataset. We are basically going to stack the blocks according to the suggestion of research paper and train our model accordingly.\n",
        "\n",
        "![alt text](https://cv-tricks.com/wp-content/uploads/2019/07/ResNet50_architecture-1.png)\n",
        "\n",
        "Dotted lines are used in network whenever the dimension of residue is different than the output. So at those places, we adjust the residue according to the output using convolution operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD2qSISb9jw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self,block,num_layers,classes=10):\n",
        "    super().__init__()\n",
        "    self.input_planes=64\n",
        "    self.conv1 = nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self.layer_x(block,64,num_layers[0],stride=1)\n",
        "    self.layer2 = self.layer_x(block,128,num_layers[1],stride=2)\n",
        "    self.layer3 = self.layer_x(block,256,num_layers[2],stride=2)\n",
        "    self.layer4 = self.layer_x(block,512,num_layers[3],stride=2)\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=4,stride=1)\n",
        "    self.fc  = nn.Linear(512*block.expansion,classes) \n",
        "\n",
        "  def layer_x(self,block,planes,num_layers,stride):\n",
        "    layers = []\n",
        "    layers.append(block(self.input_planes,planes,stride=stride))\n",
        "    self.input_planes = block.expansion*planes\n",
        "    for i in range(1,num_layers):\n",
        "      layers.append(block(self.input_planes,planes))\n",
        "      self.input_planes = planes * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    out = self.avgpool(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D4Nugd8KWZX",
        "colab_type": "text"
      },
      "source": [
        "<h1> Analysis of data and implentation of network </h1>\n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32x3 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "<h2>Step 1</h2>\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "32x32x3 image --> conv1 --> 32x32x64 feature maps\n",
        "\n",
        "<h2>Step 2</h2>\n",
        "\n",
        "    self.layer1 = self.layer_x(block,64,num_layers[0],stride=1)\n",
        "\n",
        "We will break it into 2 parts\n",
        "  1. **Overview** - \n",
        "32x32x64 --> layer1x3 --> 32x32x256\n",
        "  2. **Detailed** - \n",
        "\n",
        "  residue = 32x32x64\n",
        "\n",
        "*   32x32x64 --> conv1 --> 32x32x64\n",
        "*   32x32x64 --> conv2 --> 32x32x64\n",
        "*   32x32x64 --> conv2 --> 32x32x256 (output of bottleNeck)\n",
        "\n",
        "  residue is not equal to output !! So,\n",
        "\n",
        "\n",
        "    self.dim_change = nn.Sequential(nn.Conv2d(input_planes,planes*self.expansion,kernel_size=1,stride=stride),\n",
        "                                      nn.BatchNorm2d(planes*self.expansion))\n",
        "                                    \n",
        "  32x32x64 --> conv2d --> 32x32x256 (Final output of bottleNeck which has to activated)\n",
        "\n",
        "Now this output will be fed to the same bottleNeck Block.\n",
        "\n",
        "Again 2 times into the block but with stride=1 - 32x32x256(prev output) --> bottleNeck --> 32x32x256(new output)\n",
        "\n",
        "\n",
        "<h2>Step 3</h2>\n",
        "\n",
        "    self.layer2 = self.layer_x(block,128,num_layers[1],stride=2)\n",
        "\n",
        "We will break it into 2 parts\n",
        "  1. **Overview** - \n",
        "32x32x256 --> layer2x4 --> 32x32x512\n",
        "  2. **Detailed** - \n",
        "\n",
        "  residue = 32x32x256\n",
        "\n",
        "*   32x32x256 --> conv1 --> 32x32x128\n",
        "*   32x32x128 --> conv2 --> 16x16x128\n",
        "*   16x16x128 --> conv2 --> 16x16x512 (output of bottleNeck)\n",
        "\n",
        "  residue is not equal to output !! So,\n",
        "\n",
        "\n",
        "    self.dim_change = nn.Sequential(nn.Conv2d(input_planes,planes*self.expansion,kernel_size=1,stride=stride),\n",
        "                                      nn.BatchNorm2d(planes*self.expansion))\n",
        "\n",
        "   32x32x256 --> conv2d --> 16x16x512 (Final output of bottleNeck which has to activated) \n",
        "\n",
        "Now this output will be fed to the same bottleNeck Block.\n",
        "\n",
        "Again 3 times into the block but with stride=1 - 16x16x512(prev output) --> bottleNeck --> 16x16x512(new output)\n",
        "\n",
        "<h2>Step 4</h2>\n",
        "\n",
        "    self.layer3 = self.layer_x(block,256,num_layers[2],stride=2)\n",
        "\n",
        "\n",
        "We will break it into 2 parts\n",
        "  1. **Overview** - \n",
        "16x16x512 --> layer3x6 --> 8x8x1024\n",
        "  2. **Detailed** - \n",
        "\n",
        "  residue = 16x16x512\n",
        "\n",
        "*   16x16x512 --> conv1 --> 16x16x256\n",
        "*   16x16x256 --> conv2 --> 8x8x256\n",
        "*   8x8x256 --> conv2 --> 8x8x1024 (output of bottleNeck)\n",
        "\n",
        "  residue is not equal to output !! So,\n",
        "\n",
        "\n",
        "    self.dim_change = nn.Sequential(nn.Conv2d(input_planes,planes*self.expansion,kernel_size=1,stride=stride),\n",
        "                                      nn.BatchNorm2d(planes*self.expansion))\n",
        "\n",
        "   16x16x512 --> conv2d --> 8x8x1024 (Final output of bottleNeck which has to activated) \n",
        "\n",
        "Now this output will be fed to the same bottleNeck Block.\n",
        "\n",
        "Again 2 times into the block but with stride=1 - 8x8x1024(prev output) --> bottleNeck --> 8x8x1024(new output)\n",
        "\n",
        "\n",
        "<h2>Step 5</h2>\n",
        "\n",
        "    self.layer3 = self.layer_x(block,512,num_layers[3],stride=2)\n",
        "\n",
        "\n",
        "We will break it into 2 parts\n",
        "  1. **Overview** - \n",
        "8x8x1024 --> layer4x3 --> 4x4x2048\n",
        "  2. **Detailed** - \n",
        "\n",
        "  residue = 8x8x1024\n",
        "\n",
        "*   8x8x1024 --> conv1 --> 8x8x512\n",
        "*   8x8x512 --> conv2 --> 4x4x512\n",
        "*   4x4x512 --> conv2 --> 4x4x2048 (output of bottleNeck)\n",
        "\n",
        "  residue is not equal to output !! So,\n",
        "\n",
        "\n",
        "    self.dim_change = nn.Sequential(nn.Conv2d(input_planes,planes*self.expansion,kernel_size=1,stride=stride),\n",
        "                                      nn.BatchNorm2d(planes*self.expansion))\n",
        "\n",
        "   8x8x1024 --> conv2d --> 4x4x2048 (Final output of bottleNeck which has to activated) \n",
        "\n",
        "Now this output will be fed to the same bottleNeck Block.\n",
        "\n",
        "Again 2 times into the block but with stride=1 - 4x4x2048(prev output) --> bottleNeck --> 4x4x2048(new output)\n",
        "\n",
        "<h2>Step 6</h2>\n",
        "\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=4,stride=1)\n",
        "\n",
        "4x4x2048 --> AvgPool --> 1x1x2048 (Output that should be unsqueezed and be fed to fully-connected layer)\n",
        "\n",
        "<h2>Step 7</h2>\n",
        "\n",
        "    self.fc  = nn.Linear(512*block.expansion,classes) \n",
        "The output is unsqueezed using -\n",
        "    \n",
        "    out = out.view(out.size(0), -1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZQ60NyW57Ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "\n",
        "  #To convert data from PIL to tensor\n",
        "  transform = transforms.Compose(\n",
        "      [transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "      )\n",
        "\n",
        "  #Load train and test set:\n",
        "  train = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
        "  trainset = torch.utils.data.DataLoader(train,batch_size=128,shuffle=True)\n",
        "\n",
        "  test = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
        "  testset = torch.utils.data.DataLoader(test,batch_size=128,shuffle=False)\n",
        "  \n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(device)\n",
        "\n",
        "  #ResNet-18 \n",
        "  #net = ResNet(baseBlock,[2,2,2,2],10)\n",
        "\n",
        "  #ResNet-50\n",
        "  net =  ResNet(bottleneck,[3,4,6,3])\n",
        "  net.to(device)\n",
        "  costFunc = nn.CrossEntropyLoss()\n",
        "  optimizer =  optim.SGD(net.parameters(),lr=0.02,momentum=0.9)\n",
        "\n",
        "  for epoch in range(1):\n",
        "    closs = 0\n",
        "    for i,batch in enumerate(trainset,0):\n",
        "        data,output = batch\n",
        "        data,output = data.to(device),output.to(device)\n",
        "        prediction = net(data)\n",
        "        loss = costFunc(prediction,output)\n",
        "        closs = loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print every 1000th time\n",
        "        if i%100 == 0:\n",
        "            print('[%d  %d] loss: %.4f'% (epoch+1,i+1,closs/1000))\n",
        "            closs = 0\n",
        "\n",
        "  correctHits=0\n",
        "  total=0\n",
        "  for batches in testset:\n",
        "      data,output = batches\n",
        "      data,output = data.to(device),output.to(device)\n",
        "      prediction = net(data)\n",
        "      _,prediction = torch.max(prediction.data,1)  #returns max as well as its index\n",
        "      total += output.size(0)\n",
        "      correctHits += (prediction==output).sum().item()\n",
        "  print('Accuracy = '+str((correctHits/total)*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk5IIBan7Gi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}